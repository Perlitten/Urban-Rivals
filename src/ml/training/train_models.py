#!/usr/bin/env python3
"""
Urban Rivals ML Model Training
–û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π –¥–ª—è Urban Rivals –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–∞
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import json
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
from sklearn.metrics import accuracy_score, mean_squared_error, classification_report
import joblib
import tensorflowjs as tfjs
from typing import Dict, Tuple, Any

class UrbanRivalsMLTrainer:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π Urban Rivals"""
    
    def __init__(self, data_dir: str = "datasets", models_dir: str = "trained_models"):
        self.data_dir = Path(data_dir)
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –º–æ–¥–µ–ª–µ–π
        (self.models_dir / "tensorflow").mkdir(exist_ok=True)
        (self.models_dir / "sklearn").mkdir(exist_ok=True)
        (self.models_dir / "tensorflowjs").mkdir(exist_ok=True)
    
    def load_training_data(self) -> Dict[str, pd.DataFrame]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        try:
            card_features = pd.read_csv(self.data_dir / "card_features.csv")
            battle_features = pd.read_csv(self.data_dir / "battle_features.csv")
            
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(card_features)} –∫–∞—Ä—Ç –∏ {len(battle_features)} –±–æ—ë–≤")
            
            return {
                'card_features': card_features,
                'battle_features': battle_features
            }
        except FileNotFoundError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ dataset.py")
            raise e
    
    def train_battle_predictor(self, battle_features: pd.DataFrame) -> Dict[str, Any]:
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –±–æ—è"""
        print("‚öîÔ∏è –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±–æ—ë–≤...")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X = battle_features[['player_total_attack', 'opponent_total_attack', 
                            'attack_difference', 'player_pills_used', 'opponent_pills_used']]
        y = battle_features['winner']
        
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=0.2, random_state=42
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ TensorFlow –º–æ–¥–µ–ª–∏
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(16, activation='relu'),
            tf.keras.layers.Dense(3, activation='softmax')  # 3 –∫–ª–∞—Å—Å–∞: player, opponent, draw
        ])
        
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # –û–±—É—á–µ–Ω–∏–µ
        history = model.fit(
            X_train_scaled, y_train,
            epochs=50,
            batch_size=32,
            validation_split=0.2,
            verbose=1
        )
        
        # –û—Ü–µ–Ω–∫–∞
        y_pred = model.predict(X_test_scaled)
        y_pred_classes = np.argmax(y_pred, axis=1)
        accuracy = accuracy_score(y_test, y_pred_classes)
        
        print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±–æ—ë–≤: {accuracy:.3f}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ TensorFlow –º–æ–¥–µ–ª–∏
        model.save(self.models_dir / "tensorflow" / "battle_predictor.h5")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∫–µ–π–ª–µ—Ä–∞ –∏ —ç–Ω–∫–æ–¥–µ—Ä–∞
        joblib.dump(scaler, self.models_dir / "sklearn" / "battle_scaler.pkl")
        joblib.dump(label_encoder, self.models_dir / "sklearn" / "battle_label_encoder.pkl")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ TensorFlow.js
        tfjs.converters.save_keras_model(
            model, 
            str(self.models_dir / "tensorflowjs" / "battle_predictor")
        )
        
        return {
            'model': model,
            'scaler': scaler,
            'label_encoder': label_encoder,
            'accuracy': accuracy,
            'history': history
        }
    
    def train_card_recommender(self, card_features: pd.DataFrame, battle_features: pd.DataFrame) -> Dict[str, Any]:
        """–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫–∞—Ä—Ç"""
        print("üÉè –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫–∞—Ä—Ç...")
        
        # –°–æ–∑–¥–∞—ë–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –∫–∞—Ä—Ç –≤ –±–æ—è—Ö
        card_success_rates = {}
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π –∫–∞—Ä—Ç—ã
        for _, battle in battle_features.iterrows():
            winner = battle['winner']
            if winner in ['player', 'opponent']:
                # –ó–¥–µ—Å—å —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–∞—Ä—Ç–∞—Ö –≤ –±–æ—è—Ö
                attack_diff = battle['attack_difference']
                success_score = 1 if attack_diff > 0 else 0
                
                # –ü—Å–µ–≤–¥–æ-—Å–≤—è–∑—ã–≤–∞–Ω–∏–µ —Å –∫–∞—Ä—Ç–∞–º–∏ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–∞ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞)
                card_id = f"card_{np.random.randint(1, len(card_features) + 1)}"
                if card_id not in card_success_rates:
                    card_success_rates[card_id] = []
                card_success_rates[card_id].append(success_score)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
        for card_id in card_success_rates:
            card_success_rates[card_id] = np.mean(card_success_rates[card_id])
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        X = card_features[['clan_encoded', 'rarity_encoded', 'max_power', 'max_damage', 
                          'has_ability', 'power_damage_ratio', 'total_stats']]
        
        # –°–æ–∑–¥–∞—ë–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (—Ä–µ–π—Ç–∏–Ω–≥ –∫–∞—Ä—Ç—ã)
        y = []
        for _, card in card_features.iterrows():
            card_id = card['card_id']
            success_rate = card_success_rates.get(card_id, 0.5)  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.5
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            rating = success_rate * 0.7 + (card['total_stats'] / 20) * 0.3
            y.append(rating)
        
        y = np.array(y)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ TensorFlow –º–æ–¥–µ–ª–∏
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(16, activation='relu'),
            tf.keras.layers.Dense(1, activation='sigmoid')  # –†–µ–π—Ç–∏–Ω–≥ –æ—Ç 0 –¥–æ 1
        ])
        
        model.compile(
            optimizer='adam',
            loss='mse',
            metrics=['mae']
        )
        
        # –û–±—É—á–µ–Ω–∏–µ
        history = model.fit(
            X_train_scaled, y_train,
            epochs=100,
            batch_size=32,
            validation_split=0.2,
            verbose=1
        )
        
        # –û—Ü–µ–Ω–∫–∞
        y_pred = model.predict(X_test_scaled)
        mse = mean_squared_error(y_test, y_pred)
        
        print(f"‚úÖ MSE –º–æ–¥–µ–ª–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∫–∞—Ä—Ç: {mse:.4f}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model.save(self.models_dir / "tensorflow" / "card_recommender.h5")
        joblib.dump(scaler, self.models_dir / "sklearn" / "card_scaler.pkl")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ TensorFlow.js
        tfjs.converters.save_keras_model(
            model, 
            str(self.models_dir / "tensorflowjs" / "card_recommender")
        )
        
        return {
            'model': model,
            'scaler': scaler,
            'mse': mse,
            'history': history
        }
    
    def train_strategy_classifier(self, card_features: pd.DataFrame) -> Dict[str, Any]:
        """–û–±—É—á–∞–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∫–æ–ª–æ–¥"""
        print("üéØ –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π...")
        
        # –°–æ–∑–¥–∞—ë–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∫–∞—Ä—Ç
        strategies = []
        strategy_labels = []
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∫–æ–ª–æ–¥—ã –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        for _ in range(5000):
            # –°–ª—É—á–∞–π–Ω–∞—è –∫–æ–ª–æ–¥–∞ –∏–∑ 4 –∫–∞—Ä—Ç
            deck = card_features.sample(4)
            
            avg_power = deck['max_power'].mean()
            avg_damage = deck['max_damage'].mean()
            total_stats = deck['total_stats'].sum()
            clan_diversity = deck['clan_encoded'].nunique()
            ability_count = deck['has_ability'].sum()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
            if avg_power > 7.5:
                strategy = 'power_focused'
            elif avg_damage > 6:
                strategy = 'damage_focused'
            elif clan_diversity <= 2:
                strategy = 'mono_clan'
            elif ability_count >= 3:
                strategy = 'ability_focused'
            else:
                strategy = 'balanced'
            
            strategies.append([avg_power, avg_damage, total_stats, clan_diversity, ability_count])
            strategy_labels.append(strategy)
        
        X = np.array(strategies)
        y = np.array(strategy_labels)
        
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=0.2, random_state=42
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Random Forest –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
        rf_model.fit(X_train_scaled, y_train)
        rf_accuracy = rf_model.score(X_test_scaled, y_test)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ TensorFlow –º–æ–¥–µ–ª–∏
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(16, activation='relu'),
            tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')
        ])
        
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # –û–±—É—á–µ–Ω–∏–µ
        history = model.fit(
            X_train_scaled, y_train,
            epochs=50,
            batch_size=32,
            validation_split=0.2,
            verbose=1
        )
        
        # –û—Ü–µ–Ω–∫–∞
        tf_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)[1]
        
        print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å Random Forest: {rf_accuracy:.3f}")
        print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å TensorFlow –º–æ–¥–µ–ª–∏: {tf_accuracy:.3f}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        model.save(self.models_dir / "tensorflow" / "strategy_classifier.h5")
        joblib.dump(rf_model, self.models_dir / "sklearn" / "strategy_rf.pkl")
        joblib.dump(scaler, self.models_dir / "sklearn" / "strategy_scaler.pkl")
        joblib.dump(label_encoder, self.models_dir / "sklearn" / "strategy_label_encoder.pkl")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ TensorFlow.js
        tfjs.converters.save_keras_model(
            model, 
            str(self.models_dir / "tensorflowjs" / "strategy_classifier")
        )
        
        return {
            'tf_model': model,
            'rf_model': rf_model,
            'scaler': scaler,
            'label_encoder': label_encoder,
            'tf_accuracy': tf_accuracy,
            'rf_accuracy': rf_accuracy
        }
    
    def create_model_metadata(self, models_info: Dict[str, Any]):
        """–°–æ–∑–¥–∞—ë—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        print("üìã –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...")
        
        metadata = {
            'version': '1.0.0',
            'created': pd.Timestamp.now().isoformat(),
            'models': {
                'battle_predictor': {
                    'type': 'classification',
                    'accuracy': models_info['battle']['accuracy'],
                    'input_features': ['player_total_attack', 'opponent_total_attack', 
                                     'attack_difference', 'player_pills_used', 'opponent_pills_used'],
                    'output_classes': ['player', 'opponent', 'draw'],
                    'description': '–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ–±–µ–¥–∏—Ç–µ–ª—è –±–æ—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∫–∞—Ä—Ç –∏ –ø–∏–ª—é–ª—å'
                },
                'card_recommender': {
                    'type': 'regression',
                    'mse': models_info['card']['mse'],
                    'input_features': ['clan_encoded', 'rarity_encoded', 'max_power', 'max_damage', 
                                     'has_ability', 'power_damage_ratio', 'total_stats'],
                    'output_range': [0, 1],
                    'description': '–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å –∫–∞—Ä—Ç—ã –≤ —Ç–µ–∫—É—â–µ–π –∏–≥—Ä–æ–≤–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏'
                },
                'strategy_classifier': {
                    'type': 'classification',
                    'accuracy': models_info['strategy']['tf_accuracy'],
                    'input_features': ['avg_power', 'avg_damage', 'total_stats', 'clan_diversity', 'ability_count'],
                    'output_classes': ['power_focused', 'damage_focused', 'mono_clan', 'ability_focused', 'balanced'],
                    'description': '–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∫–æ–ª–æ–¥—ã'
                }
            },
            'usage_instructions': {
                'tensorflow_js': '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª–∏ –∏–∑ –ø–∞–ø–∫–∏ tensorflowjs/ –≤ –±—Ä–∞—É–∑–µ—Ä–µ',
                'preprocessing': '–ù–æ—Ä–º–∞–ª–∏–∑—É–π—Ç–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Å–∫–µ–π–ª–µ—Ä–æ–≤',
                'inference': '–ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ tf.loadLayersModel() –≤ JavaScript'
            }
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        with open(self.models_dir / "models_metadata.json", 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print("‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ models_metadata.json")
        return metadata
    
    def train_all_models(self):
        """–û–±—É—á–∞–µ—Ç –≤—Å–µ –º–æ–¥–µ–ª–∏"""
        print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö ML –º–æ–¥–µ–ª–µ–π...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        data = self.load_training_data()
        
        models_info = {}
        
        # 1. –û–±—É—á–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä –±–æ—ë–≤
        battle_model = self.train_battle_predictor(data['battle_features'])
        models_info['battle'] = battle_model
        
        # 2. –û–±—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å –∫–∞—Ä—Ç
        card_model = self.train_card_recommender(data['card_features'], data['battle_features'])
        models_info['card'] = card_model
        
        # 3. –û–±—É—á–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        strategy_model = self.train_strategy_classifier(data['card_features'])
        models_info['strategy'] = strategy_model
        
        # 4. –°–æ–∑–¥–∞—ë–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = self.create_model_metadata(models_info)
        
        print("\nüéâ –í—Å–µ –º–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã!")
        print(f"üìÅ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.models_dir}")
        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è:")
        print(f"  ‚öîÔ∏è –ü—Ä–µ–¥–∏–∫—Ç–æ—Ä –±–æ—ë–≤: {battle_model['accuracy']:.3f} —Ç–æ—á–Ω–æ—Å—Ç—å")
        print(f"  üÉè –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å –∫–∞—Ä—Ç: {card_model['mse']:.4f} MSE")
        print(f"  üéØ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {strategy_model['tf_accuracy']:.3f} —Ç–æ—á–Ω–æ—Å—Ç—å")
        
        return models_info, metadata

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
    print("ü§ñ Urban Rivals ML Training Pipeline")
    print("=====================================")
    
    trainer = UrbanRivalsMLTrainer()
    models_info, metadata = trainer.train_all_models()
    
    print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("üì¶ –ì–æ—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è TensorFlow.js –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ trained_models/tensorflowjs/")
    print("üîß –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–µ–π: trained_models/models_metadata.json")
    
    return models_info, metadata

if __name__ == "__main__":
    main() 